{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f8f2145",
   "metadata": {},
   "source": [
    "## Spark  DataFrames Project \n",
    "### Walmart Stock \n",
    "@Author - Amruta Abhyankar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "243cde51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a Simple Spark Session\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc30b490",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('project').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede1d1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Walmart Stock CSV File, have Spark infer data types.\n",
    "df = spark.read.csv(\"/Users/amrutaabhyankar/Downloads/Python-and-Spark-for-Big-Data-master/Spark_DataFrame_Project_Exercise/walmart_stock.csv\",\n",
    "                   header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cf56bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c98dcb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the schema \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c620edb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date='2012-01-03', Open=59.970001, High=61.060001, Low=59.869999, Close=60.330002, Volume=12668800, Adj Close=52.619234999999996),\n",
       " Row(Date='2012-01-04', Open=60.209998999999996, High=60.349998, Low=59.470001, Close=59.709998999999996, Volume=9593300, Adj Close=52.078475),\n",
       " Row(Date='2012-01-05', Open=59.349998, High=59.619999, Low=58.369999, Close=59.419998, Volume=12768200, Adj Close=51.825539),\n",
       " Row(Date='2012-01-06', Open=59.419998, High=59.450001, Low=58.869999, Close=59.0, Volume=8069400, Adj Close=51.45922),\n",
       " Row(Date='2012-01-09', Open=59.029999, High=59.549999, Low=58.919998, Close=59.18, Volume=6679300, Adj Close=51.616215000000004)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing firt five rows\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3e09c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Date='2012-01-03', Open=59.970001, High=61.060001, Low=59.869999, Close=60.330002, Volume=12668800, Adj Close=52.619234999999996)\n",
      "\n",
      "\n",
      "Row(Date='2012-01-04', Open=60.209998999999996, High=60.349998, Low=59.470001, Close=59.709998999999996, Volume=9593300, Adj Close=52.078475)\n",
      "\n",
      "\n",
      "Row(Date='2012-01-05', Open=59.349998, High=59.619999, Low=58.369999, Close=59.419998, Volume=12768200, Adj Close=51.825539)\n",
      "\n",
      "\n",
      "Row(Date='2012-01-06', Open=59.419998, High=59.450001, Low=58.869999, Close=59.0, Volume=8069400, Adj Close=51.45922)\n",
      "\n",
      "\n",
      "Row(Date='2012-01-09', Open=59.029999, High=59.549999, Low=58.919998, Close=59.18, Volume=6679300, Adj Close=51.616215000000004)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in df.head(5):\n",
    "    print(row)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "113c3bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|summary|      Date|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
      "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|  count|      1258|              1258|             1258|             1258|             1258|             1258|             1258|\n",
      "|   mean|      null| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
      "| stddev|      null|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
      "|    min|2012-01-03|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
      "|    max|2016-12-30|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
      "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Learn about the DataFrame\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a18a3d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- summary: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: string (nullable = true)\n",
      " |-- High: string (nullable = true)\n",
      " |-- Low: string (nullable = true)\n",
      " |-- Close: string (nullable = true)\n",
      " |-- Volume: string (nullable = true)\n",
      " |-- Adj Close: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a4db5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import format_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c1f8e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fccfe00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------+--------+-------------+\n",
      "|summary|    Open|    High|     Low|   Close|       Volume|\n",
      "+-------+--------+--------+--------+--------+-------------+\n",
      "|  count|1,258.00|1,258.00|1,258.00|1,258.00|     1,258.00|\n",
      "|   mean|   72.36|   72.84|   71.92|   72.39| 8,222,093.00|\n",
      "| stddev|    6.77|    6.77|    6.74|    6.76| 4,519,780.00|\n",
      "|    min|   56.39|   57.06|   56.30|   56.42| 2,094,900.00|\n",
      "|    max|   90.80|   90.97|   89.25|   90.47|80,898,100.00|\n",
      "+-------+--------+--------+--------+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(result['summary'],\n",
    "             format_number(result['Open'].cast('float'),2).alias('Open'),\n",
    "             format_number(result['High'].cast('float'),2).alias('High'),\n",
    "             format_number(result['Low'].cast('float'),2).alias('Low'),\n",
    "             format_number(result['Close'].cast('float'),2).alias('Close'),\n",
    "             format_number(result['Volume'].cast('int'),2).alias('Volume')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a05a9",
   "metadata": {},
   "source": [
    "### Create a new dataframe with a column called HV Ratio that is the ratio of the High Price versus volume of a stock traded for a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e97c7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            HV Ratio|\n",
      "+--------------------+\n",
      "|4.819714653321546E-6|\n",
      "|6.290848613094555E-6|\n",
      "|4.669412994783916E-6|\n",
      "|7.367338463826307E-6|\n",
      "|8.915604778943901E-6|\n",
      "|8.644477436914568E-6|\n",
      "|9.351828421515645E-6|\n",
      "| 8.29141562102703E-6|\n",
      "|7.712212102001476E-6|\n",
      "|7.071764823529412E-6|\n",
      "|1.015495466386981E-5|\n",
      "|6.576354146362592...|\n",
      "| 5.90145296180676E-6|\n",
      "|8.547679455011844E-6|\n",
      "|8.420709512685392E-6|\n",
      "|1.041448341728929...|\n",
      "|8.316075414862431E-6|\n",
      "|9.721183814992126E-6|\n",
      "|8.029436027707578E-6|\n",
      "|6.307432259386365E-6|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.withColumn(\"HV Ratio\",df[\"High\"]/df[\"Volume\"])\n",
    "df2.select('HV Ratio').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450cfb6c",
   "metadata": {},
   "source": [
    "### What day had the Peak High Price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb457a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+-----------------+-----------------+-----------------+--------+-----------------+\n",
      "|      Date|             Open|             High|              Low|            Close|  Volume|        Adj Close|\n",
      "+----------+-----------------+-----------------+-----------------+-----------------+--------+-----------------+\n",
      "|2015-01-13|        90.800003|        90.970001|            88.93|        89.309998| 8215400|        83.825448|\n",
      "|2015-01-08|        89.209999|90.66999799999999|            89.07|        90.470001|12713600|84.91421600000001|\n",
      "|2015-01-09|            90.32|        90.389999|            89.25|        89.349998| 8522500|        83.862993|\n",
      "|2015-01-12|        89.360001|        90.309998|        89.220001|        90.019997| 7372500|        84.491846|\n",
      "|2015-01-23|88.41999799999999|        89.260002|        87.889999|        88.510002| 7565800|83.07458100000001|\n",
      "|2015-01-26|        88.309998|        89.160004|        88.120003|        88.629997| 4666700|        83.187207|\n",
      "|2015-01-07|        86.779999|            88.68|86.66999799999999|        88.599998| 8498400|        83.159051|\n",
      "|2015-01-14|        87.650002|        88.519997|             86.5|        86.610001|11745600|        81.291259|\n",
      "|2015-01-27|        88.279999|        88.459999|        87.260002|        87.529999| 6020500|         82.15476|\n",
      "|2015-01-22|        87.230003|        88.400002|        86.860001|        88.300003| 7123800|        82.877478|\n",
      "|2015-01-28|        88.019997|        88.230003|        86.769997|            86.82| 5936800|        81.488362|\n",
      "|2014-11-28|            86.18|        88.089996|        85.900002|        87.540001| 7820600|81.70768000000001|\n",
      "|2015-02-06|        87.260002|             88.0|        86.779999|87.33000200000001| 5617600|        81.967045|\n",
      "|2015-01-15|             87.0|        87.779999|        86.699997|        87.379997| 9412700|         82.01397|\n",
      "|2015-01-29|            87.07|        87.720001|        86.269997|        87.720001| 6522800|82.33309399999999|\n",
      "|2015-01-20|            86.82|        87.699997|        85.550003|        86.690002| 7853100|        81.366348|\n",
      "|2015-01-16|        87.199997|        87.459999|        86.230003|        86.769997| 8408900|81.44143000000001|\n",
      "|2014-12-31|87.08000200000001|        87.440002|        85.860001|        85.879997| 4151400|        80.606085|\n",
      "|2015-02-10|        86.620003|        87.410004|86.41999799999999|        87.290001| 5732100|          81.9295|\n",
      "|2015-01-30|        86.779999|        87.360001|        84.900002|        84.980003|10280200|         79.76136|\n",
      "+----------+-----------------+-----------------+-----------------+-----------------+--------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(df['High'].desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c70349c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date='2015-01-13', Open=90.800003, High=90.970001, Low=88.93, Close=89.309998, Volume=8215400, Adj Close=83.825448)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.orderBy(df['High'].desc()).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d99a1dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Date='2015-01-13', Open=90.800003, High=90.970001, Low=88.93, Close=89.309998, Volume=8215400, Adj Close=83.825448)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.orderBy(df['High'].desc()).head(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "151cf80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015-01-13'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.orderBy(df['High'].desc()).head(1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a307a4",
   "metadata": {},
   "source": [
    "### Mean of the Close Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b02edb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(Close)|\n",
      "+-----------------+\n",
      "|72.38844998012726|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "df.select(mean(\"Close\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662d74a9",
   "metadata": {},
   "source": [
    "### Calculating the Max and Mean of the Volume Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a04f2378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|max(Volume)|min(Volume)|\n",
      "+-----------+-----------+\n",
      "|   80898100|    2094900|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max,min\n",
    "df.select(max(\"Volume\"),min(\"Volume\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a8c68",
   "metadata": {},
   "source": [
    "### How many days was the Close lower than 60 dollars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "565a18fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter('Close < 60').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c5aae62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternate way\n",
    "df.filter(df['Close']<60).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51c6b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "069e0d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.filter(df['Close']<60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "653c618f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|count(Close)|\n",
      "+------------+\n",
      "|          81|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(count('Close')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ffa3b9",
   "metadata": {},
   "source": [
    "### What percentage of the time was the High greater than 80 dolllars ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da5bc635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.141494435612083"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.filter(df[\"High\"]>80).count()/df.count())*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0f1d08",
   "metadata": {},
   "source": [
    "### What is the Pearson correaltion between high and Volume?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49b63e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "| corr(High, Volume)|\n",
      "+-------------------+\n",
      "|-0.3384326061737161|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "df.select(corr('High','Volume')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bfaeb5",
   "metadata": {},
   "source": [
    "### What is the max high per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12e2aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year\n",
    "yeardf = df.withColumn(\"Year\",year(df['Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9dc65957",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxdf = yeardf.groupBy('Year').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8728a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|Year|max(High)|\n",
      "+----+---------+\n",
      "|2015|90.970001|\n",
      "|2013|81.370003|\n",
      "|2014|88.089996|\n",
      "|2012|77.599998|\n",
      "|2016|75.190002|\n",
      "+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxdf.select('Year',\"max(High)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b0bfd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|Year|max(High)|\n",
      "+----+---------+\n",
      "|2012|77.599998|\n",
      "|2013|81.370003|\n",
      "|2014|88.089996|\n",
      "|2015|90.970001|\n",
      "|2016|75.190002|\n",
      "+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxdf.select('Year',\"max(High)\").orderBy('Year').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aaab3e",
   "metadata": {},
   "source": [
    "### What is the average Close for each Calendar Month ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "774d5ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7cbf7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthdf = df.withColumn('Month',month('Date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c127cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthavgs = monthdf.select(['Month','Close']).groupBy('Month').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e4f878c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|Month|       avg(Close)|\n",
      "+-----+-----------------+\n",
      "|    1|71.44801958415842|\n",
      "|    2|  71.306804443299|\n",
      "|    3|71.77794377570092|\n",
      "|    4|72.97361900952382|\n",
      "|    5|72.30971688679247|\n",
      "|    6| 72.4953774245283|\n",
      "|    7|74.43971943925233|\n",
      "|    8|73.02981855454546|\n",
      "|    9|72.18411785294116|\n",
      "|   10|71.57854545454543|\n",
      "|   11| 72.1110893069307|\n",
      "|   12|72.84792478301885|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "monthavgs.select(['Month','avg(Close)']).orderBy('Month').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b475b946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
